import org.apache.spark.mllib.classification.LogisticRegressionWithSGD
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.{SparkConf, SparkContext}

object LogisticRegression{
val conf = new SparkConf()                                     //建立環境變數
.setMaster("local")                                             //設定本機化處理
.setAppName("LogisticRegression ")                              //設定名稱
    val sc = new SparkContext(conf)                                 //建立環境變數案例

  def main(args: Array[String]) {
    val data = sc.textFile("c:/u.txt")							  	 //取得資料集路徑
    val parsedData = data.map { line =>							 //開始對資料集處理
      val parts = line.split('|')									 //根據逗點進行分區
      LabeledPoint(parts(0).toDouble, Vectors.dense(parts(1).map(_.toDouble))
    }.cache()                                                      //轉化資料格式
    val model = LogisticRegressionWithSGD.train(parsedData,50)		//建立模型
    val target = Vectors.dense(-1)								//建立測試值
    val resulet = model.predict(target)							//根據模型計算結果
println(resulet)  										//列印結果
}
}

